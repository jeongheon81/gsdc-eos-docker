---
# https://www.uuidgenerator.net/

bootstrap:
  ansible_cfg:
    defaults:
      stdout_callback: human_readable_stdout

group_vars_all:
  ssh_keyscan: true
  package_upgrade: false
  install_info_home: eos-install-info
  firewall_direct_rule_priority_base:
    chrony: 50
  ntp_servers: ["0.centos.pool.ntp.org iburst", "1.centos.pool.ntp.org iburst", "2.centos.pool.ntp.org iburst", "3.centos.pool.ntp.org iburst"]
  ntp_initstep_servers: ["0.centos.pool.ntp.org", "1.centos.pool.ntp.org", "2.centos.pool.ntp.org", "3.centos.pool.ntp.org"]
  cockpit_enabled: true
  cockpit_plugins:
  - cockpit-dashboard
  - cockpit-docker
  - cockpit-packagekit
  - cockpit-pcp
  - cockpit-storaged
  cockpit_admin_groups:
  - unix-group:wheel
  cockpit_rule_priority_base: 11
  container_domain: eoscluster.sdfarm.kr
  container_images:
    eos: eos-local:v4.6.5-20200110135430
    consul: consul:1.6
    consul_prometheus_exporter: prom/consul-exporter:v0.6.0
    nginx: nginx:1.17-alpine
    nginx_prometheus_exporter: nginx/nginx-prometheus-exporter:0.5.0
    grafana: grafana/grafana:latest
    prometheus: prom/prometheus:latest
    prometheus_alertmanager: prom/alertmanager:latest
    prometheus_node_exporter: prom/node-exporter:latest
    prometheus_snmp_exporter: prom/snmp-exporter:latest
    prometheus_snmp_generator: prom/snmp-generator:master
    prometheus_gmond_exporter: prom/gmond-exporter-linux-amd64:v0.0.5
    prometheus_telegram_bot: prom/telegram_bot:v0.0.1
    loki: grafana/loki:v1.2.0
    promtail: grafana/promtail:latest
  container_etc_hosts_static: {}
    # all:
    #   fq.dn1: 192.168.1.2
    # hostname.domain:
    #   fq.dn2: 192.168.1.3
  consul_port_dns: 8600
  consul_ui_alias: !unsafe "consul-ui.{{ container_domain }}"
  consul_alias: !unsafe "consul.{{ container_domain }}"
  consul_domain: !unsafe "consul.{{ container_domain }}"
  consul_datacenter: gsdc-01
  consul_primary_datacenter: !unsafe "{{ consul_datacenter }}"
  consul_ca_days: 10950
  consul_cert_days: 10949
  consul_allow_nodes: !unsafe "{{ eos_nodes }}"
  loki_address: 134.75.125.53:3100
  eos_prime_group: eos_infra_group_001
  eos_prime_cluster_domain_name: !unsafe "{{ eoscluster.sdfarm.kr }}"
  eos_instance_name: gsdc
  eos_mail_cc: sahn@kisti.re.kr
  eos_admin_user: eos-admin
  eos_admin_user_uid: 1001
  eos_admin_user_gid: 1001
  eos_use_proxy: yes
  eos_xrootd_internet_address_protocol: v4
  eos_realm: !unsafe "{{ eos_prime_cluster_domain_name|upper }}"
  eos_nodes: !unsafe "{{ eos_krb_nodes + eos_manager_nodes + eos_proxy_nodes + eos_mgm_nodes + eos_qdb_nodes + eos_fst_nodes }}"
  eos_krb_master: !unsafe "eos-krb-01.{{ eos_prime_cluster_domain_name }}"
  eos_krb_alias: !unsafe "eos-krb.{{ eos_prime_cluster_domain_name }}"
  eos_manager_alias: !unsafe "eos-manager.{{ eos_prime_cluster_domain_name }}"
  eos_proxy_alias: !unsafe "eos-proxy.{{ eos_prime_cluster_domain_name }}"
  eos_mgm_alias: !unsafe "eos-mgm.{{ eos_prime_cluster_domain_name }}"
  eos_qdb_alias: !unsafe "eos-qdb.{{ eos_prime_cluster_domain_name }}"
  eos_mgm_prime_master: !unsafe "eos-mgm-01.{{ eos_prime_cluster_domain_name }}"
  eos_mgm_masters:
  - !unsafe "{{ eos_mgm_prime_master }}"
  - !unsafe "{{ eos_mgm_prime_master }}"
  eos_mgm_url_regular: !unsafe "root://{{ eos_mgm_alias }}:1094"
  eos_mgm_url_proxied: !unsafe "root://{{ eos_proxy_alias }}:1094//root://{{ eos_mgm_alias }}:1094"
  eos_mq_alias: !unsafe "eos-mgm.{{ eos_prime_cluster_domain_name }}"
  eos_broker_url: !unsafe "root://{{ eos_mq_alias }}:1097//eos/"
  eos_fuse_mgm_alias: !unsafe "{{ eos_mgm_alias }}"
  eos_default_fs_space_name: default
  eos_default_fs_insertion_status: rw
  eos_default_number_of_fst: !unsafe "{{ eos_fst_nodes|length }}"
  eos_use_qdb: yes
  qdb_clusters: !unsafe "{{ eos_qdb_nodes }}"
  qdb_port: 7777
  qdb_cluster_uuid: 689d996e-c5ee-4bdb-a9be-6689e52a4340
  qdb_redis_databases:
  - /var/lib/quarkdb/node-01
  - /var/lib/quarkdb/node-02
  - /var/lib/quarkdb/node-03
  krb5_conf:
    libdefaults:
      default_realm: !unsafe "{{ eos_realm }}"
    realms:
    - name: EOSCLUSTER.SDFARM.KR
      config:
        kdc: eos-krb-01.eoscluster.sdfarm.kr
        admin_server: eos-krb-01.eoscluster.sdfarm.kr
        master_kdc: eos-krb-01.eoscluster.sdfarm.kr
        default_domain: eoscluster.sdfarm.kr
    - name: SDFARM.KR
      config:
        kdc:
        - ipa1.sdfarm.kr
        - ipa2.sdfarm.kr
        - ipa.sdfarm.kr
        admin_server: ipa1.sdfarm.kr
    - name: EOSCLUSTER.SUT.AC.TH
      config:
        kdc: eos-krb-01.eoscluster.sut.ac.th
        admin_server: eos-krb-01.eoscluster.sut.ac.th
    domain_realms:
    - domain: .eoscluster.sdfarm.kr
      realm: EOSCLUSTER.SDFARM.KR
    - domain: eoscluster.sdfarm.kr
      realm: EOSCLUSTER.SDFARM.KR
    - domain: .sdfarm.kr
      realm: SDFARM.KR
    - domain: sdfarm.kr
      realm: SDFARM.KR
    - domain: .eoscluster.sut.ac.th
      realm: EOSCLUSTER.SUT.AC.TH
    - domain: eoscluster.sut.ac.th
      realm: EOSCLUSTER.SUT.AC.TH
    capaths:
    - realm: EOSCLUSTER.SDFARM.KR
      config:
      - target_realm: SDFARM.KR
        next_realm: "."
      - target_realm: EOSCLUSTER.SUT.AC.TH
        next_realm: "."
    - realm: EOSCLUSTER.SUT.AC.TH
      config:
      - target_realm: EOSCLUSTER.SDFARM.KR
        next_realm: "."
  krb5_cross_realm_authentication_password_id:
  - target_realm: SDFARM.KR
    password_id: 1
  - target_realm: EOSCLUSTER.SUT.AC.TH
    password_id: 2
  admin:
    id: !unsafe "{{ vault_admin.id }}"
    password: !unsafe "{{ vault_admin.password }}"
  manager:
    id: !unsafe "{{ vault_manager.id }}"
    password: !unsafe "{{ vault_manager.password }}"
  random_passwords: !unsafe "{{ vault_random_passwords }}"

host_default: &host_default
  ansible_user: root
  ansible_port: 22

container_default: &container_default
  network: !unsafe "{{ container_domain }}"
  domain: !unsafe "{{ container_domain }}"
  etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

eos_container_default: &eos_container_default
  <<: *container_default
  image: !unsafe "{{ container_images.eos }}"



consul_server_config_default: &consul_server_config_default
  image: !unsafe "{{ container_images.consul }}"
  nginx_proxy_image: !unsafe "{{ container_images.nginx }}"
  consul_exporter_image: !unsafe "{{ container_images.consul_prometheus_exporter }}"
  consul_bind_interface_name_pattern: ^br1$
  consul_configs:
    server: true
    bootstrap_expect: !unsafe "{{ consul_server_nodes|length|int }}"
    enable_local_script_checks: true
    auto_encrypt:
      allow_tls: true
    verify_incoming: true
    verify_outgoing: true
    verify_server_hostname: true
    cert_file: !unsafe "/consul/config/{{ consul_datacenter }}-server-{{ consul_domain }}-$(name).pem"
    key_file: !unsafe "/consul/config/{{ consul_datacenter }}-server-{{ consul_domain }}-$(name)-key.pem"

consul_client_config_default: &consul_client_config_default
  image: !unsafe "{{ container_images.consul }}"
  nginx_proxy_image: !unsafe "{{ container_images.nginx }}"
  consul_bind_interface_name_pattern: ^br1$
  consul_configs:
    ui: true
    enable_local_script_checks: true
    auto_encrypt:
      tls: true

host_group:
- name: eos_infra_dc01_rack01
  group_vars:
    eos_geotag: kisti::gsdc::g01
  hosts:
  - name: jbod-mgmt-01.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.53/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      # - conn_name: bridge-br2
      #   ifname: br2
      #   stp: no
      #   slave_conn_name: uplink-br2
      #   slave_ifname: eno2
      #   conflict_conn_name: System eno2
      #   conflict_type: ethernet
      #   ip4: 192.168.125.53/24
      #   gw4: ''
      #   mtu: 1500
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.53
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_server:
        - name: consul-01
          <<: *container_default
          network_mode: host
          <<: *consul_server_config_default
        grafana_server:
        - name: grafana-01
          <<: *container_default
          image: !unsafe "{{ container_images.grafana }}"
          network_mode: host
          grafana_plugins:
          - grafana-clock-panel
          - grafana-piechart-panel
        loki_server_local:
        - name: loki-01
          <<: *container_default
          image: !unsafe "{{ container_images.loki }}"
          network_mode: host
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

  - name: jbod-mgmt-02.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.55/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.55
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_client:
        - name: consul-02
          <<: *container_default
          network_mode: host
          <<: *consul_client_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

  - name: jbod-mgmt-03.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.57/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.57
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_client:
        - name: consul-03
          <<: *container_default
          network_mode: host
          <<: *consul_client_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

- name: eos_infra_dc01_rack02
  group_vars:
    eos_geotag: kisti::gsdc::g02
  hosts:
  - name: jbod-mgmt-04.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.59/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.59
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_server:
        - name: consul-04
          <<: *container_default
          network_mode: host
          <<: *consul_server_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

  - name: jbod-mgmt-05.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.73/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.73
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_client:
        - name: consul-05
          <<: *container_default
          network_mode: host
          <<: *consul_client_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

  - name: jbod-mgmt-06.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.75/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.75
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_client:
        - name: consul-06
          <<: *container_default
          network_mode: host
          <<: *consul_client_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

- name: eos_infra_dc01_rack03
  group_vars:
    eos_geotag: kisti::gsdc::g03
  hosts:
  - name: jbod-mgmt-07.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.244/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.244
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_server:
        - name: consul-07
          <<: *container_default
          network_mode: host
          <<: *consul_server_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

  - name: jbod-mgmt-08.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.246/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.246
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_client:
        - name: consul-08
          <<: *container_default
          network_mode: host
          <<: *consul_client_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

  - name: jbod-mgmt-09.sdfarm.kr
    <<: *host_default
    host_vars:
      network_bridge:
      - conn_name: bridge-br1
        ifname: br1
        stp: no
        slave_conn_name: uplink-br1
        slave_ifname: p4p1
        conflict_conn_name: System p4p1
        conflict_type: ethernet
        ip4: 134.75.125.251/24
        gw4: 134.75.125.1
        mtu: 1500
        dns4: !unsafe "{{ network_dns[0].dns4|default(omit) }}"
        dns4_search: !unsafe "{{ network_dns[0].dns4_search|default(omit) }}"
        dns6: !unsafe "{{ network_dns[0].dns6|default(omit) }}"
        dns6_search: !unsafe "{{ network_dns[0].dns6_search|default(omit) }}"
      container_network:
      - name: !unsafe "{{ container_domain }}"
        gateway: 134.75.125.251
        subnet: 134.75.125.0/24
        masquerade: false
        bridge_name: br1
      containers:
        consul_client:
        - name: consul-09
          <<: *container_default
          network_mode: host
          <<: *consul_client_config_default
        loki_promtail:
        - name: !unsafe "loki-promtail-{{ ansible_hostname }}"
          image: !unsafe "{{ container_images.promtail }}"
          etc_hosts: !unsafe "{{ container_etc_hosts[ansible_fqdn]|default(omit) }}"

        # eos_krb:
        # - name: eos-krb-01
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.30
        #   network_aliases:
        #   - eos-krb
        #   - !unsafe "{{ eos_krb_alias }}"
        #   krb_realm: !unsafe "{{ eos_realm }}"
        # eos_qdb:
        # - name: eos-qdb-01
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.35
        #   network_aliases: &qdb_network_aliases
        #   - eos-qdb
        #   - !unsafe "{{ eos_qdb_alias }}"
        #   redis_database: /var/lib/quarkdb/qdb-01
        # - name: eos-qdb-02
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.36
        #   network_aliases: *qdb_network_aliases
        #   redis_database: /var/lib/quarkdb/qdb-02
        # - name: eos-qdb-03
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.37
        #   network_aliases: *qdb_network_aliases
        #   redis_database: /var/lib/quarkdb/qdb-03
        # eos_proxy:
        # - name: eos-proxy-01
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.34
        #   network_aliases:
        #   - eos-proxy
        #   - !unsafe "{{ eos_proxy_alias }}"
        #   xrd_roles:
        #   - proxy
        # eos_mgm:
        # - name: eos-mgm-01
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.23
        #   network_aliases:
        #   - eos-mgm
        #   - !unsafe "{{ eos_mgm_alias }}"
        #   xrd_roles:
        #   - mq
        #   - mgm
        #   mgm_host: !unsafe "{{ eos_mgm_masters[0] }}"
        #   mgm_host_target: !unsafe "{{ eos_mgm_masters[1] }}"
        # - name: eos-mgm-02
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.24
        #   xrd_roles:
        #   - mq
        #   - mgm
        #   mgm_host: !unsafe "{{ eos_mgm_masters[1] }}"
        #   mgm_host_target: !unsafe "{{ eos_mgm_masters[0] }}"
        # eos_fst:
        # - name: eos-fst-0001
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.38
        #   xrd_roles:
        #   - fst
        #   data_dir: /data/disk0001
        #   nfs_volumes:
        #   - name: data
        #     dest: /data
        #     device: :/ifs/service/eos_kisti/fst01
        #     options: addr=pool0.gsn3.sdfarm.kr,rw,nfsvers=3
        #   fst_fsid: 1
        #   fst_uuid: 627bcd30-1af6-4525-a0c9-8a958a863b91
        #   fst_space: !unsafe "{{ eos_default_fs_space_name }}"
        #   fst_status: !unsafe "{{ eos_default_fs_insertion_status }}"
        # - name: eos-fst-0002
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.39
        #   xrd_roles:
        #   - fst
        #   data_dir: /data/disk0002
        #   nfs_volumes:
        #   - name: data
        #     dest: /data
        #     device: :/ifs/service/eos_kisti/fst02
        #     options: addr=pool0.gsn3.sdfarm.kr,rw,nfsvers=3
        #   fst_fsid: 2
        #   fst_uuid: 7469a2ee-ecbf-4a46-ac42-9d1f1adaa7e3
        #   fst_space: !unsafe "{{ eos_default_fs_space_name }}"
        #   fst_status: !unsafe "{{ eos_default_fs_insertion_status }}"
        # - name: eos-fst-0003
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.40
        #   xrd_roles:
        #   - fst
        #   data_dir: /data/disk0003
        #   nfs_volumes:
        #   - name: data
        #     dest: /data
        #     device: :/ifs/service/eos_kisti/fst03
        #     options: addr=pool0.gsn3.sdfarm.kr,rw,nfsvers=3
        #   fst_fsid: 3
        #   fst_uuid: 7b30fa24-5b9a-426d-9af8-98a62c341e19
        #   fst_space: !unsafe "{{ eos_default_fs_space_name }}"
        #   fst_status: !unsafe "{{ eos_default_fs_insertion_status }}"
        # eos_manager:
        # - name: eos-manager-01
        #   <<: *eos_container_default
        #   ipv4_address: 134.75.125.20
        #   network_aliases:
        #   - eos-manager
        #   - !unsafe "{{ eos_manager_alias }}"
        #   xrd_roles:
        #   - eosxd
        #   logs:
        #   - fuse/fuse.main.log
        # grafana_server:
        # - name: grafana-01
        #   <<: *container_default
        #   image: !unsafe "{{ container_images.grafana }}"
        #   ipv4_address: 134.75.125.50
        #   nfs_volumes:
        #   - name: data
        #     dest: /var/lib/grafana
        #     device: :/ifs/service/eos_kisti/grafana-01
        #     options: addr=pool0.gsn3.sdfarm.kr,rw,nfsvers=4
        #   grafana_plugins:
        #   - grafana-clock-panel
        #   - grafana-piechart-panel
        #   loki_address: 134.75.125.51:3100
        # grafana_loki:
        # - name: grafana-loki
        #   <<: *container_default
        #   image: !unsafe "{{ container_images.loki }}"
        #   ipv4_address: 134.75.125.51
        # grafana_promtail:
        # - name: grafana-promtail-eos-kisti-01
        #   <<: *container_default
        #   image: !unsafe "{{ container_images.promtail }}"
        #   ipv4_address: 134.75.125.52
        #   loki_address: 134.75.125.51:3100
- name: eos_infra_dc01
  group_vars:
    firewall_internal_zone_sources:
    - 134.75.123.0/24
    - 134.75.124.0/24
    - 134.75.125.0/24
    - 134.75.127.0/24
    - 192.168.123.0/24
    - 192.168.124.0/24
    - 192.168.125.0/24
    - 192.168.127.0/24
    - 192.168.2.0/24
    firewall_cooperation_zone_sources: []
    firewall_forward_between_internal_zone: no
    firewall_forward_enable_nat: no
    firewall_forward_nat_out_interface: br2
    firewall_forward_nat_negative_sources:
    - 192.168.0.0/16
    network_dns:
    - conn_name: bridge-br1
      dns4: ["134.75.123.233", "134.75.123.231"]
      dns4_search: ["sdfarm.kr", "private.lo", "bmc.lo"]
    network_routes: []
    # - conn_name: bridge-br2
    #   ipv4_list:
    #   - ip: 192.168.123.0/24
    #     nh: 192.168.125.1
    #   - ip: 192.168.124.0/24
    #     nh: 192.168.125.1
    #   - ip: 192.168.127.0/24
    #     nh: 192.168.125.1
    #   - ip: 192.168.2.0/24
    #     nh: 192.168.125.1
    docker_users:
    - localadmin
    container_network_user_firewall_rules: >-
      {%- raw -%}
      {% set br1 = network_bridge[0].ip4.split('/')[0] -%}
      {% set final_result = [] -%}
      {{ final_result.append({ 'tag': 'related established', 'rule': 'ipv4 filter DOCKER-USER 1 -m conntrack --ctstate RELATED,ESTABLISHED -j RETURN' }) -}}
      {{ final_result.append({ 'tag': 'icmp', 'rule': 'ipv4 filter DOCKER-USER 2 -p icmp -j RETURN' }) -}}
      {{ final_result.append({ 'tag': 'Check null (DOCKER)', 'rule': "ipv4 filter DOCKER-USER 4 -p tcp -m tcp --tcp-flags FIN,SYN,RST,PSH,ACK,URG NONE -m limit --limit 5/min -j LOG --log-prefix 'DU_null: '" }) -}}
      {{ final_result.append({ 'tag': 'Check syn-flood (DOCKER)', 'rule': "ipv4 filter DOCKER-USER 6 -p tcp -m tcp '!' --tcp-flags FIN,SYN,RST,ACK SYN -m state --state NEW -m limit --limit 5/min -j LOG --log-prefix 'DU_syn-fld: '" }) -}}
      {{ final_result.append({ 'tag': 'Check XMAS (DOCKER)', 'rule': "ipv4 filter DOCKER-USER 8 -p tcp -m tcp --tcp-flags FIN,SYN,RST,PSH,ACK,URG FIN,SYN,RST,PSH,ACK,URG -m limit --limit 5/min -j LOG --log-prefix 'DU_XMAS: '" }) -}}
      {{ final_result.append({ 'tag': 'multi-cast address', 'rule': 'ipv4 filter DOCKER-USER 10 -d 224.0.0.0/4 -j RETURN' }) -}}
      {{ final_result.append({ 'tag': 'bridge-br1 address', 'rule': 'ipv4 filter DOCKER-USER 11 -d ' + br1 + ' -j RETURN' }) -}}
      {% for address in firewall_internal_zone_sources -%}
      {{   final_result.append({ 'tag': 'internal address ' + '%02d'|format(loop.index), 'rule': 'ipv4 filter DOCKER-USER ' + (100+loop.index)|string + ' -s ' + address + ' -j RETURN' }) -}}
      {% endfor -%}
      {% for address in firewall_cooperation_zone_sources -%}
      {{   final_result.append({ 'tag': 'cooperation address ' + '%02d'|format(loop.index), 'rule': 'ipv4 filter DOCKER-USER ' + (200+loop.index)|string + ' -s ' + address + ' -j RETURN' }) -}}
      {% endfor -%}
      {{ final_result.append({ 'tag': 'drop log no bridge-br1 address', 'rule': "ipv4 filter DOCKER-USER 998 '!' -d " + br1 + " -j LOG --log-prefix 'DU_DROP: '" }) -}}
      {{ final_result.append({ 'tag': 'drop no bridge-br1 address',     'rule': "ipv4 filter DOCKER-USER 999 '!' -d " + br1 + " -j DROP" }) -}}
      {% for node in consul_server_nodes + consul_client_nodes -%}
      {{   final_result.append({ 'tag': 'consul DNS UDP port redirection on PREROUTING '+'%02d'|format(loop.index), 'rule': 'ipv4 nat PREROUTING '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p udp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns|string }) -}}
      {{   final_result.append({ 'tag': 'consul DNS TCP port redirection on PREROUTING '+'%02d'|format(loop.index), 'rule': 'ipv4 nat PREROUTING '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p tcp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns|string }) -}}
      {{   final_result.append({ 'tag': 'consul DNS UDP port redirection on OUTPUT '+'%02d'|format(loop.index),     'rule': 'ipv4 nat OUTPUT '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p udp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns|string }) -}}
      {{   final_result.append({ 'tag': 'consul DNS TCP port redirection on OUTPUT '+'%02d'|format(loop.index),     'rule': 'ipv4 nat OUTPUT '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p tcp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns|string }) -}}
      {% endfor -%}
      {{ final_result }}
      {%- endraw -%}
    # container_network_user_firewall_rules: >-
    #   {%- raw -%}
    #   {% set br1 = network_bridge[0].ip4.split('/')[0] -%}
    #   {% set br2 = network_bridge[1].ip4.split('/')[0] -%}
    #   {% set final_result = [] -%}
    #   {{ final_result.append({ 'tag': 'related established', 'rule': 'ipv4 filter DOCKER-USER 1 -m conntrack --ctstate RELATED,ESTABLISHED -j RETURN' }) -}}
    #   {{ final_result.append({ 'tag': 'icmp', 'rule': 'ipv4 filter DOCKER-USER 2 -p icmp -j RETURN' }) -}}
    #   {{ final_result.append({ 'tag': 'null', 'rule': 'ipv4 filter DOCKER-USER 4 -p tcp -m tcp --tcp-flags FIN,SYN,RST,PSH,ACK,URG NONE -m limit --limit 5/min -j LOG --log-prefix "DU_null: "' }) -}}
    #   {{ final_result.append({ 'tag': 'syn-flood', 'rule': 'ipv4 filter DOCKER-USER 6 -p tcp -m tcp ! --tcp-flags FIN,SYN,RST,ACK SYN -m state --state NEW -m limit --limit 5/min -j LOG --log-prefix "DU_syn-fld: "' }) -}}
    #   {{ final_result.append({ 'tag': 'XMAS', 'rule': 'ipv4 filter DOCKER-USER 8 -p tcp -m tcp --tcp-flags FIN,SYN,RST,PSH,ACK,URG FIN,SYN,RST,PSH,ACK,URG -m limit --limit 5/min -j LOG --log-prefix "DU_XMAS: "' }) -}}
    #   {{ final_result.append({ 'tag': 'multi-cast address', 'rule': 'ipv4 filter DOCKER-USER 10 -d 224.0.0.0/4 -j RETURN' }) -}}
    #   {{ final_result.append({ 'tag': 'bridge-br1 address', 'rule': 'ipv4 filter DOCKER-USER 11 -d ' + br1 + ' -j RETURN' }) -}}
    #   {{ final_result.append({ 'tag': 'bridge-br2 address', 'rule': 'ipv4 filter DOCKER-USER 12 -s 192.168.0.0/16 -d ' +  br2 + ' -j RETURN' }) -}}
    #   {% for address in firewall_internal_zone_sources -%}
    #   {{   final_result.append({ 'tag': 'internal address ' + '%02d'|format(loop.index), 'rule': 'ipv4 filter DOCKER-USER ' + (100+loop.index)|string + ' -s ' + address + ' -j RETURN' }) -}}
    #   {% endfor -%}
    #   {% for address in firewall_cooperation_zone_sources -%}
    #   {{   final_result.append({ 'tag': 'cooperation address ' + '%02d'|format(loop.index), 'rule': 'ipv4 filter DOCKER-USER ' + (200+loop.index)|string + ' -s ' + address + ' -j RETURN' }) -}}
    #   {% endfor -%}
    #   {{ final_result.append({ 'tag': 'drop log no bridge-br2 address', 'rule': 'ipv4 filter DOCKER-USER 996 -s 192.168.0.0/16 ! -d ' + br2 + ' -j LOG --log-prefix "DU_DROP: "' }) -}}
    #   {{ final_result.append({ 'tag': 'drop no bridge-br2 address',     'rule': 'ipv4 filter DOCKER-USER 997 -s 192.168.0.0/16 ! -d ' + br2 + ' -j DROP' }) -}}
    #   {{ final_result.append({ 'tag': 'drop log no bridge-br1 address', 'rule': 'ipv4 filter DOCKER-USER 998 ! -d ' + br1 + ' -j LOG --log-prefix "DU_DROP: "' }) -}}
    #   {{ final_result.append({ 'tag': 'drop no bridge-br1 address',     'rule': 'ipv4 filter DOCKER-USER 999 ! -d ' + br1 + ' -j DROP' }) -}}
    #   {% for node in consul_client_nodes -%}
    #   {{   final_result.append({ 'tag': 'consul DNS UDP port redirection on PREROUTING '+'%02d'|format(loop.index), 'rule': 'ipv4 nat PREROUTING '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p udp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns }) -}}
    #   {{   final_result.append({ 'tag': 'consul DNS TCP port redirection on PREROUTING '+'%02d'|format(loop.index), 'rule': 'ipv4 nat PREROUTING '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p tcp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns }) -}}
    #   {{   final_result.append({ 'tag': 'consul DNS UDP port redirection on OUTPUT '+'%02d'|format(loop.index),     'rule': 'ipv4 nat OUTPUT '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p udp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns }) -}}
    #   {{   final_result.append({ 'tag': 'consul DNS TCP port redirection on OUTPUT '+'%02d'|format(loop.index),     'rule': 'ipv4 nat OUTPUT '+(500+loop.index)|string+' -d '+container_etc_hosts.all[node]+' -p tcp --dport 53 -j DNAT --to-destination '+container_etc_hosts.all[node]+':'+consul_port_dns }) -}}
    #   {% endfor -%}
    #   {{ final_result }}
    #   {%- endraw -%}
    eos_mgm_masters:
    - !unsafe "{{ eos_mgm_prime_master }}"
    - !unsafe "eos-mgm-02.{{ container_domain }}"
  children:
  - name: eos_infra_dc01_rack01
  - name: eos_infra_dc01_rack02
  - name: eos_infra_dc01_rack03
- name: eos_infra_all
  group_vars: {}
  children:
  - name: eos_infra_dc01


group_vars_all_auto: >-
  {% set final_result = {} -%}
  {% set eos_cluster_domain_names = [] -%}
  {# generate: eos_krb_nodes, eos_manager_nodes, eos_proxy_nodes, eos_mgm_nodes, eos_qdb_nodes, eos_fst_nodes, grafana_server_nodes, consul_ui_nodes, consul_server_nodes, consul_client_nodes, loki_cassandra_nodes, loki_server_nodes, memcached_server_nodes -#}
  {% for container_type in ['consul_server', 'consul_client', 'grafana_server', 'eos_krb', 'eos_manager', 'eos_proxy', 'eos_mgm', 'eos_qdb', 'eos_fst'] -%}
  {%   set result = [] -%}
  {%   for group in host_group|default({}) -%}
  {%     for host in group.hosts|default({}) -%}
  {%       if host.host_vars.containers is defined -%}
  {%         set container_domain = host.host_vars.container_domain|default(group.group_vars.container_domain|default(group_vars_all.container_domain|default(''))) -%}
  {{         result.append(host.host_vars.containers[container_type]|default([])|to_json|from_json|json_query('[].join(`.`, [ name, `'+container_domain+'` ])')) -}}
  {%         if container_type is match('eos_') -%}
  {{           eos_cluster_domain_names.append(container_domain) -}}
  {%         endif -%}
  {%       endif -%}
  {%     endfor -%}
  {%   endfor -%}
  {{   final_result.update({ container_type+'_nodes': result|flatten }) -}}
  {% endfor -%}
  {# generate: container_etc_hosts -#}
  {%   set result = {} -%}
  {%   set pre_result_all = [] -%}
  {%   for group in host_group|default({}) -%}
  {%     for host in group.hosts|default({}) -%}
  {%       set pre_result = [] -%}
  {%       for other_group in host_group|default({}) -%}
  {%         for other_host in other_group.hosts|default({}) -%}
  {%           if other_host.name != host.name -%}
  {%             if other_host.host_vars.containers is defined -%}
  {%               set containers = other_host.host_vars.containers|dict2items|to_json|from_json|json_query('[?value[*].ipv4_address]')|items2dict -%}
  {%               set container_aliases = other_host.host_vars.containers|dict2items|to_json|from_json|json_query('[?value[*].ipv4_address]|[?value[*].network_aliases]')|items2dict -%}
  {{               pre_result.append( containers|to_json|from_json|json_query('*[*][{ name: name, domain: domain, ipv4_address: ipv4_address, network_aliases: network_aliases }]|[]|[]') ) -}}
  {%               set containers = other_host.host_vars.containers|dict2items|to_json|from_json|json_query('[?value[*].network_mode]')|items2dict -%}
  {%               for container_name in containers|to_json|from_json|json_query('*[?network_mode == `host`][ name ]|[]|[]') -%}
  {%                 set container_domain = other_host.host_vars.container_domain|default(other_group.group_vars.container_domain|default(group_vars_all.container_domain|default(''))) -%}
  {{                 pre_result.append( { 'name': container_name, 'domain': container_domain, 'ipv4_address': other_host.host_vars.network_bridge[0].ip4.split('/')[0] } ) -}}
  {%               endfor -%}
  {%             endif -%}
  {{             pre_result.append( { 'name': other_host.name.split('.')[0], 'domain': other_host.name.split('.')[1:]|join('.'), 'ipv4_address': other_host.host_vars.network_bridge[0].ip4.split('/')[0] } ) -}}
  {%           endif -%}
  {%         endfor -%}
  {%       endfor -%}
  {{       result.update({ host.name: pre_result|flatten|to_json|from_json|json_query('[*].{ key: join(`.`,[name, domain]), value: ipv4_address }') }) -}}
  {{       result.update({ host.name: pre_result|flatten|to_json|from_json|json_query('[?network_aliases]')|subelements('network_aliases', skip_missing=True)|to_json|from_json|json_query('[*].{ key: [1], value: [0].ipv4_address }')|default([], true)|union(result[host.name]) }) -}}
  {%       if host.host_vars.containers is defined -%}
  {%         set containers = host.host_vars.containers|dict2items|to_json|from_json|json_query('[?value[*].ipv4_address]')|items2dict -%}
  {{         pre_result_all.append( containers|to_json|from_json|json_query('*[*][{ name: name, domain: domain, ipv4_address: ipv4_address, network_aliases: network_aliases }]|[]|[]') ) -}}
  {%         set containers = host.host_vars.containers|dict2items|to_json|from_json|json_query('[?value[*].network_mode]')|items2dict -%}
  {%         for container_name in containers|to_json|from_json|json_query('*[?network_mode == `host`][ name ]|[]|[]') -%}
  {%           set container_domain = host.host_vars.container_domain|default(group.group_vars.container_domain|default(group_vars_all.container_domain|default(''))) -%}
  {{           pre_result_all.append( { 'name': container_name, 'domain': container_domain, 'ipv4_address': host.host_vars.network_bridge[0].ip4.split('/')[0] } ) -}}
  {%         endfor -%}
  {%       endif -%}
  {{       pre_result_all.append( { 'name': host.name.split('.')[0], 'domain': host.name.split('.')[1:]|join('.'), 'ipv4_address': host.host_vars.network_bridge[0].ip4.split('/')[0] } ) -}}
  {%     endfor -%}
  {%   endfor -%}
  {{   result.update({ 'all': pre_result_all|flatten|to_json|from_json|json_query('[*].{ key: join(`.`,[name, domain]), value: ipv4_address }') }) -}}
  {{   result.update({ 'all': pre_result_all|flatten|to_json|from_json|json_query('[?network_aliases]')|subelements('network_aliases', skip_missing=True)|to_json|from_json|json_query('[*].{ key: [1], value: [0].ipv4_address }')|default([], true)|union(result['all']) }) -}}
  {{   final_result.update({ 'container_etc_hosts_items': result }) -}}
  {{   final_result.update({ 'container_etc_hosts': '{% set result = {} %}{% for key in container_etc_hosts_items  %}{{ result.update({ key: container_etc_hosts_items[key]|items2dict|combine(container_etc_hosts_static[key]|default({}))|combine(container_etc_hosts_static["all"]|default({})) }) }}{% endfor %}{{ result }}' }) -}}
  {# generate: container_etc_hosts_aliases -#}
  {%   set result = {} -%}
  {%   set pre_result_all = [] -%}
  {%   for group in host_group|default({}) -%}
  {%     for host in group.hosts|default({}) -%}
  {%       set pre_result = [] -%}
  {%       for other_group in host_group|default({}) -%}
  {%         for other_host in other_group.hosts|default({}) -%}
  {%           if other_host.name != host.name -%}
  {%             if other_host.host_vars.containers is defined -%}
  {%               set container_domain = other_host.host_vars.container_domain|default(other_group.group_vars.container_domain|default(group_vars_all.container_domain|default(''))) -%}
  {%               set containers = other_host.host_vars.containers|dict2items|to_json|from_json|json_query('[?value[*].ipv4_address]|[?value[*].network_aliases]')|items2dict -%}
  {{               pre_result.append( containers|to_json|from_json|json_query('*[*][{ network_aliases: network_aliases, ipv4_address: ipv4_address }]|[]|[]') ) -}}
  {%             endif -%}
  {%           endif -%}
  {%         endfor -%}
  {%       endfor -%}
  {{       result.update({ host.name: pre_result|flatten|to_json|from_json|json_query('[?network_aliases]')|subelements('network_aliases', skip_missing=True)|to_json|from_json|json_query('[*].{ key: [1], value: [0].ipv4_address }') }) -}}
  {%       if host.host_vars.containers is defined -%}
  {%         set container_domain = host.host_vars.container_domain|default(group.group_vars.container_domain|default(group_vars_all.container_domain|default(''))) -%}
  {%         set containers = host.host_vars.containers|dict2items|to_json|from_json|json_query('[?value[*].ipv4_address]|[?value[*].network_aliases]')|items2dict-%}
  {{         pre_result_all.append( containers|to_json|from_json|json_query('*[*][{ network_aliases: network_aliases, ipv4_address: ipv4_address }]|[]|[]') ) -}}
  {%       endif -%}
  {%     endfor -%}
  {%   endfor -%}
  {{   result.update({ 'all': pre_result_all|flatten|to_json|from_json|json_query('[?network_aliases]')|subelements('network_aliases', skip_missing=True)|to_json|from_json|json_query('[*].{ key: [1], value: [0].ipv4_address }') }) -}}
  {{   final_result.update({ 'container_etc_hosts_aliases_items': result }) -}}
  {{   final_result.update({ 'container_etc_hosts_aliases': '{% set result = {} %}{% for key in container_etc_hosts_aliases_items  %}{{ result.update({ key: container_etc_hosts_aliases_items[key]|items2dict }) }}{% endfor %}{{ result }}' }) -}}
  {# -#}
  {{ final_result }}
